Learning Spatio-Temporal Density Derivatives in
Smoothed Particle Hydrodynamics Using Graph Neural
Networks
===
#### Author: Jakob Semmler

This repository contains the code used to train the models for my bachelor's thesis. It also contains notebooks, result data, figures, and other code generated for the thesis.

## Requirements

The work uses **Python 3.10.11** on **Ubuntu (WSL)** with GPU acceleration with many different packages.
A mismatch in the versions of the packages used will cause conflicts.
Especially between Numpy, Torch, the Tensorboard Reporting, Ray Tune and the Open3D Continuous Convolutional Layer. The layer also does not work in a Windows system. Other Python versions may also cause issues.

<sup> (It took almost two months to find a configuration that worked.)</sup>


## Packages
The packages needed to run the experiments and generate the graphs can be found here.
See freeze.txt for specific versions and other accompanying packages.

```bash
pip install --upgrade pip

pip install tensorpack zstandard msgpack msgpack_numpy
pip install numpy==1.23.5
pip install open3d
pip install -r https://raw.githubusercontent.com/isl-org/Open3D-ML/master/requirements-torch-cuda.txt

pip install torch_geometric
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-1.13.0+cu116.html
pip install pytorch-lightning

pip install "ray[tune]"
pip install tensorboard

pip install jupyterlab
pip install matplotlib plotly
pip install ipywidgets vtk pyvista trame panel colorcet kaleido
```



## Usage
Individual models can be trained using `train_network.py`. It also accepts hyperparameters. Several examples can be found in `utils/train_networks_sequentially.sh`. Hyperparameter optimizations are performed via `search_hparams.py`.

### Example 1
Train a network using the default baseline parameters. The run will be named <em>default1</em> in tensorboard. Please check the parameters set in `train_networks.py` to make sure they are what you want.

```python train_network.py --name "default1"```

### Example 2
Initialize a network using the parameters generated by Ray Tune. This is useful if you want to examine found models more closely. Again, we provide a seed. In the default configuration of `train_network.py` this causes the initialization of weights and biases to be deterministic. The training process itself can also be made deterministic if desired. See the code comments.

```python train_network.py --name "00031_run1" --seed 278346 --params_path "${trainer_dir}/00031_31/params.json"```

### Example 3
Continue training from a checkpoint generated by Pytorch Lightning or Ray Tune. It is strongly recommended to provide a parameter path when loading a checkpoint.

```python train_network.py --checkpoint_path "${trainer_dir}/00030_30/rank_0/logs/srch/checkpoints/last.ckpt" --params_path "${trainer_dir}/00030_30/params.json"```

### Example 4
To perform **hyperparameter optimization**, run `search_hparams.py`. You can adjust the search space in the file. By default, three configurations are trained in parallel on the GPU. You can configure GPU splitting and all other training settings in the file.

You can collect the results of a search by configuring and running `utils/collect_results.py`. It will output all hyperparameters and performance as a csv-file.

# Datasets
The samples of the datasets from the DeepLagrangianFluids ([link](https://github.com/isl-org/DeepLagrangianFluids#data-download)) repository can be used without further modification. However, training can be dramatically accelerated by pre-computing the density and density gradient data.

The datasets are loaded as Pytorch Lightning datamodules. When the data is loaded, it is first checked if gradient data exists. If not, the data is automatically calculated on the GPU in a pre-training initialization step.

To preprocess the datasets for faster training, run e.g. in a Jupyter notebook:
```python
from utils.train_helper import *.
prepocess_dataset_files('datasets/data/sequential', device='cuda')
```
Technical notes: The code expects a dataset to be a flat directory containing the compressed .zst sample files. To train with a subset of these datasets, simply use fewer files. The first time a dataset is loaded, a file `_simulation_states.pkl` is created. It contains a filename-to-concrete-sample map to allow random training over all samples. If .zst files are deleted or added in the dataset, remove this file. It will be regenerated automatically if needed.

## Examples from the training process
These images are automatically generated during the training process and can be viewed with tensorboard. Navigate to the directory `~/ray_results` after a hyperparameter search and run `tensorboard --logdir='.'`. The board is available at `http://localhost:6006/`.


Hyperparameter search: Train loss vs. val loss

<img src="utils/images/first_hparam_search_train_loss_step.svg" width="300" />
<img src="utils/images/first_hparam_search_val_loss_step.svg" width="300" />

This is after 30 epochs.

### Predicting the density gradient (Before and after training; val dataset)
![](utils/images/eval_start.png)
![](utils/images/eval_end.png)

### Predicting the density gradient (Before and after training; train dataset)
![](utils/images/train_start.png)
![](utils/images/train_end.png)

### Each particle and their density gradient prediction. (Before and after training; val and train dataset)
![](utils/images/eval_start_2d.png)
![](utils/images/eval_end_2d.png)
![](utils/images/train_start_2d.png)
![](utils/images/train_end_2d.png)

### Loss
![](utils/images/loss.png)

Loss after 30 epochs.

## System
The experiments were performed on an Intel Core i7-3770K processor and an Nvidia
GeForce GTX 1080 Ti graphics processing unit.

Kernel: `Linux DESKTOP-S12DUI1 5.15.90.3-microsoft-standard-WSL2 #1 SMP Wed Jul 12 00:26:42 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux`